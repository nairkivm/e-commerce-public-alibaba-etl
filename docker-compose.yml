version: '3.8'

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always
    networks:
      - my_network

  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    ports:
      - "2181:2181"
    networks:
      - my_network

  kafka:
    image: wurstmeister/kafka:2.12-2.2.1
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9092,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    networks:
      - my_network

  airflow-webserver:
    build: 
      context: .
      dockerfile: Dockerfile-airflow
      args:
        CREDENTIAL: ${CREDENTIAL}
    image: my_airflow_image:latest
    environment:
      - AIRFLOW__CORE__EXECUTOR=${AIRFLOW__CORE__EXECUTOR}
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=${AIRFLOW__CORE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=${AIRFLOW__CORE__LOAD_EXAMPLES}
      - AIRFLOW__CORE__DAGS_FOLDER=${AIRFLOW__CORE__DAGS_FOLDER}
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW__WEBSERVER__SECRET_KEY}
    ports:
      - "8080:8080"
    command: >
      bash -c "airflow db init &&
               airflow users create --username ${ADMIN_USERNAME} --password ${ADMIN_PASSWORD} --firstname ${ADMIN_FIRSTNAME} --lastname ${ADMIN_LASTNAME} --role Admin --email ${ADMIN_EMAIL} &&
               airflow webserver"
    volumes:
      - ./dags:/opt/airflow/dags:z
      - ./etl-logs:/opt/airflow/etl-logs:z
      - ./utils:/opt/airflow/utils:z
      - ./data_source:/opt/airflow/data_source:z
    env_file:
      - .env
    depends_on:
      - postgres
    networks:
      - my_network

  airflow-scheduler:
    build: 
      context: .
      dockerfile: Dockerfile-airflow
      args:
        CREDENTIAL: ${CREDENTIAL}
    image: my_airflow_image:latest
    environment:
      - AIRFLOW__CORE__EXECUTOR=${AIRFLOW__CORE__EXECUTOR}
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=${AIRFLOW__CORE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=${AIRFLOW__CORE__LOAD_EXAMPLES}
      - AIRFLOW__CORE__DAGS_FOLDER=${AIRFLOW__CORE__DAGS_FOLDER}
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW__WEBSERVER__SECRET_KEY}
    command: >
      bash -c "airflow db init && airflow scheduler"
    volumes:
      - ./dags:/opt/airflow/dags:z
      - ./etl-logs:/opt/airflow/etl-logs:z
      - ./utils:/opt/airflow/utils:z
      - ./data_source:/opt/airflow/data_source:z
    env_file:
      - .env
    depends_on:
      - postgres
    networks:
      - my_network

  etl-stream:
    build:
      context: .
      dockerfile: Dockerfile-stream
      args:
        CREDENTIAL: ${CREDENTIAL}
    volumes:
      - .:/usr/src/app
    working_dir: /usr/src/app
    env_file:
      - .env
    networks:
      - my_network

  producer-stream:
    build: 
      context: .
      dockerfile: Dockerfile-stream
      args:
        CREDENTIAL: ${CREDENTIAL}
    volumes:
      - .:/usr/src/app
    working_dir: /usr/src/app
    env_file:
      - .env
    networks:
      - my_network

volumes:
  postgres_data:

networks:
  my_network:
